{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Background and Preprocessing Steps:\n",
    "The data provided was in separate CSV files for each participant, with each record representing the participant's turn and the corresponding features. The train folder contained 87 files, while the test folder had 20 files. To simplify the process, all CSVs from the train folder were combined into a single file. The participant ID was extracted from the CSV file name and added as a feature to the consolidated data. The \"labels.csv\" file was used to map the participant ID to their corresponding gender and depression labels. The test data underwent a similar treatment. As a result, two files were generated: \"final_training_data\" with 13,625 records and 91 columns, and \"final_testing_data\" with 3,280 records and 91 columns. In addition to the 88 audio features provided, three columns were added: \"participant_id,\" \"gender,\" and \"depression\". Here is a before and after for the training dataset.\n",
    "\n",
    "<div style=\"display: flex;\">\n",
    "  <div style=\"flex: 1; margin-right: 20px;\">\n",
    "    <h4>Training Data - BEFORE Preprocessing</h4>\n",
    "    <img src=\"../Images/before-training-data.png\" width=\"300\" alt=\"Training Data - BEFORE Preprocessing\"/>\n",
    "  </div>\n",
    "  <div style=\"flex: 1;\">\n",
    "    <h4>Training Data - AFTER Preprocessing</h4>\n",
    "    <img src=\"../Images/after-training-data.png\" width=\"400\" alt=\"Training Data - AFTER Preprocessing\"/>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-project-python-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
